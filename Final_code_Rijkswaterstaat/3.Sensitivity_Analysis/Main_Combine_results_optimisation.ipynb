{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Combining Results for Multiple Days\n",
    "\n",
    "This notebook outlines the code for consolidating optimal results across multiple days. The process involves assigning a score to each location based on its frequency of occurrence. Additionally, there is the option to multiply this score by the probability of occurrence for a specific day. The ultimate objective is to select a predefined number of road inspectors from the locations with the highest scores, while adhering to specific constraints.\n",
    "\n",
    "To assess the performance of these selected locations, an approach is used where each location is mirrored on the opposite side of the road. This mirroring is essential as the road network lacks data to easily navigate off and on ramps for travel in the opposite direction.\n",
    "\n",
    "In the final step, the optimization model is executed, using only the selected locations as candidates instead of all candidate locations. The primary purpose is to calculate the performance of these chosen locations, offering insights into the efficiency and effectiveness of the road inspectors locations.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bab26b23d3748411"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pygeos in c:\\users\\klaas sicking\\documents\\studie\\studie\\aerospace\\advanced data science\\pro\\venv\\lib\\site-packages (0.14)\n",
      "Requirement already satisfied: numpy>=1.13 in c:\\users\\klaas sicking\\documents\\studie\\studie\\aerospace\\advanced data science\\pro\\venv\\lib\\site-packages (from pygeos) (1.26.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install pygeos"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-03T18:27:56.710538700Z",
     "start_time": "2023-11-03T18:27:53.590616Z"
    }
   },
   "id": "d28575e97896f684"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fuzzywuzzy in c:\\users\\klaas sicking\\documents\\studie\\studie\\aerospace\\advanced data science\\pro\\venv\\lib\\site-packages (0.18.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install fuzzywuzzy"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-03T18:27:58.261287200Z",
     "start_time": "2023-11-03T18:27:56.715928100Z"
    }
   },
   "id": "d3bad7386123d331"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Klaas Sicking\\Documents\\studie\\studie\\Aerospace\\advanced data science\\Pro\\venv\\lib\\site-packages\\fuzzywuzzy\\fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "import functions\n",
    "import folium\n",
    "import pandas as pd \n",
    "import geopandas as gpd \n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import ast\n",
    "from fuzzywuzzy import fuzz\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt \n",
    "import math\n",
    "import shapely.wkt\n",
    "import time\n",
    "from gurobipy import *\n",
    "from functions import DutchRDtoWGS84\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "warnings.simplefilter(\"ignore\")\n",
    "%matplotlib notebook"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-03T18:27:59.431629200Z",
     "start_time": "2023-11-03T18:27:58.261287200Z"
    }
   },
   "id": "15e966993842336e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Preparation\n",
    "\n",
    "This section involves loading and preparing various data sources. It includes reading candidate locations, weights, road network, and incident data.\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6e9a43c5961b25bb"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "unique_candidates = pd.read_csv('input/unique_candidates.csv')\n",
    "df = pd.read_csv('input/weight.csv')\n",
    "gdf = gpd.read_file('input/Snelheid_Wegvakken.shp')\n",
    "road_network = gdf\n",
    "G = nx.read_graphml(\"input/highway_nodes_DiGraph_nb.xml\")\n",
    "all_incidents = pd.read_csv(\"input/Incidents_clean.csv\")\n",
    "all_incidents['starttime_new'] = pd.to_datetime(all_incidents['starttime_new'])\n",
    "\n",
    "df_without_weight = pd.read_csv('input/result.csv')\n",
    "sums_without_weight = df_without_weight.drop(['Date'], axis=1).sum()\n",
    "df_with_weight = pd.read_csv('input/weight.csv')\n",
    "sums_with_weight = df_with_weight.drop(['Date', 'Event_Count'], axis=1).sum()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-03T18:28:13.313726Z",
     "start_time": "2023-11-03T18:27:59.431629200Z"
    }
   },
   "id": "3402e59298ff2312"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def process_and_save_files(input_folder, output_file):\n",
    "    \"\"\"\n",
    "    Process and aggregate the optimisation results from multiple days.\n",
    "\n",
    "    Args:\n",
    "        input_folder (str): Path to the folder containing input files.\n",
    "        output_file (str): Path to the output CSV file.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame containing aggregated data for all files.\n",
    "\n",
    "    This function reads and processes data from multiple files in the input folder. Each file is expected to have\n",
    "    columns 'X', 'Y', and 'Index'. The 'Index' column is used to aggregate data into a single DataFrame where\n",
    "    each row represents a file. The resulting DataFrame is saved to the output CSV file.\n",
    "\n",
    "    \"\"\"\n",
    "    file_list = os.listdir(input_folder)\n",
    "    all_days = pd.DataFrame(columns=range(0, 1936))\n",
    "\n",
    "    for file in file_list:\n",
    "        file_path = os.path.join(input_folder, file)\n",
    "        df = pd.read_csv(file_path, sep=\" \", header=None, names=['X', 'Y', 'Index'])\n",
    "        new_row = [0] * 1936\n",
    "\n",
    "        for index_val in df.iloc[:, 2]:\n",
    "            idx = int(index_val)\n",
    "            new_row[idx] = 1\n",
    "\n",
    "        all_days.loc[file] = new_row\n",
    "\n",
    "    all_days.to_csv(output_file, index_label='Date')\n",
    "    return all_days\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-03T18:28:13.331784800Z",
     "start_time": "2023-11-03T18:28:13.319791800Z"
    }
   },
   "id": "25207876dd9dff8d"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# Example usage of the function\n",
    "input_folder = \"input/output_files/\"\n",
    "output_file = 'result/result.csv'\n",
    "result_df = process_and_save_files(input_folder, output_file)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-03T18:28:13.581537200Z",
     "start_time": "2023-11-03T18:28:13.333314400Z"
    }
   },
   "id": "5ca99959bdda8d9d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Aggregating Optimization Results for Road Inspector Locations\n",
    "\n",
    "This code snippet processes and aggregates optimal road inspector locations obtained from multiple days. It reads data from a folder containing several files, each representing the optimal locations for road inspectors on a specific day. Each file is expected to have columns 'X', 'Y,' and 'Index.' The 'Index' column is used to consolidate the data into a single DataFrame, where each row represents the optimal locations for road inspectors on one day. The resulting DataFrame is then saved to an output CSV file.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "df63f4fe505add8b"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def get_weighted_results(pdf_file, result_file, output_file):\n",
    "    \"\"\"\n",
    "    Combine and apply weights to result data using probabilities from a PDF file.\n",
    "\n",
    "    Parameters:\n",
    "        pdf_file (str): Path to the PDF data CSV file containing the probabilities for each date.\n",
    "        result_file (str): Path to the result data CSV file with results for various dates.\n",
    "        output_file (str): Path to the output CSV file to save the combined and weighted results.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Processed and merged DataFrame with weighted values.\n",
    "    \"\"\"\n",
    "    # Read the PDF data and format the date column\n",
    "    pdf_df = pd.read_csv(pdf_file)\n",
    "    pdf_df['Date'] = pd.to_datetime(pdf_df['Date'], infer_datetime_format=True)\n",
    "\n",
    "    # Read the result data and format the date column\n",
    "    result_df = pd.read_csv(result_file)\n",
    "    result_df['Date'] = pd.to_datetime(result_df['Date'], infer_datetime_format=True)\n",
    "\n",
    "    # Merge the DataFrames\n",
    "    merged_df = pd.merge(result_df, pdf_df, on='Date', how='inner')\n",
    "\n",
    "    # Calculate weighted values\n",
    "    columns_to_multiply = [col for col in result_df.columns if col != 'Date']\n",
    "    for col in columns_to_multiply:\n",
    "        merged_df[col] = merged_df[col] * merged_df['PDF_Value']\n",
    "\n",
    "    # Save the result to a new CSV file\n",
    "    merged_df.drop('PDF_Value', axis=1, inplace=True)\n",
    "    merged_df.to_csv(output_file, index=False)\n",
    "\n",
    "    return merged_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-03T18:28:13.600434600Z",
     "start_time": "2023-11-03T18:28:13.581537200Z"
    }
   },
   "id": "44c294f159c3c8e5"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "pdf_file = 'result/pdf.csv'\n",
    "result_file = 'result/result.csv'\n",
    "output_file = 'result/weight.csv'\n",
    "weights = get_weighted_results(pdf_file, result_file, output_file)\n",
    "weights = df_with_weight.drop(['Date', 'Event_Count'], axis=1).sum()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-03T18:28:14.301827400Z",
     "start_time": "2023-11-03T18:28:13.600434600Z"
    }
   },
   "id": "2aed9baad009a058"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Transformation for Desired Format\n",
    "\n",
    "In order to achieve the desired data format, we perform the following steps:\n",
    "\n",
    "1. Create a list of scores, including cumulative scores in ascending order.\n",
    "2. Generate a corresponding list of locations.\n",
    "\n",
    "Additionally, you can to choose whether to include correction for day occurrence in the data. (The code below uses the scores with occurrence correction)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f6d4b01aa3a6ef3a"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def get_score_and_location_lists(sums_df, unique_candidates_df=unique_candidates):\n",
    "    \"\"\"\n",
    "    Convert a matrix (sums_df) containing scores for selected locations into two lists:\n",
    "    \n",
    "    1. A score list: A list of scores for each selected location.\n",
    "    2. A location list: A list of tuples, each containing the x and y coordinates of a selected location.\n",
    "\n",
    "    Args:\n",
    "        sums_df (DataFrame): A DataFrame containing the scores for selected locations.\n",
    "        unique_candidates_df (DataFrame, optional): A DataFrame with information about the selected locations. Defaults to 'unique_candidates'.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of scores for each selected location.\n",
    "        list: A list of location tuples (x, y) for each selected location.\n",
    "    \"\"\"\n",
    "    sum_df = sums_df.reset_index()\n",
    "    sum_df.columns = ['Index', 'Sum']\n",
    "\n",
    "    results_df = unique_candidates_df.copy()\n",
    "    combined_df = pd.concat([results_df, sum_df], axis=1)\n",
    "    combined_df = combined_df.sort_values(by='Sum', ascending=False)\n",
    "    combined_df = combined_df.drop(columns='Index')\n",
    "\n",
    "    score_list = combined_df['Sum'].tolist()\n",
    "    location_df = combined_df[['first_point_x', 'first_point_y']]\n",
    "    location_list = list(location_df.to_records(index=False))\n",
    "    return score_list, location_list"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-03T18:28:14.321768700Z",
     "start_time": "2023-11-03T18:28:14.301827400Z"
    }
   },
   "id": "cb29a31037c7d4fb"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "score_list, location_list = get_score_and_location_lists(weights)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-03T18:28:14.361671Z",
     "start_time": "2023-11-03T18:28:14.321768700Z"
    }
   },
   "id": "211a71d082d6f4a1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Selecting the Top 120 Locations\n",
    "\n",
    "In this step, we aim to identify the best locations among a list of candidates, each assigned a score. Our goal is to select the top 120 locations with the highest scores. To ensure a diverse and effective selection, we have applied specific constraints:\n",
    "\n",
    "1. **Minimum Euclidean Distance:** We impose a constraint that the Euclidean distance between selected inspector locations must exceed a minimum threshold.\n",
    "\n",
    "2. **Minimum Path Distance:** Another constraint we enforce is that the path distance between selected locations must be greater than a specified minimum value.\n",
    "\n",
    "These constraints help prevent the selection of closely located locations with high scores, ultimately leading to a more balanced and efficient choice of inspector locations.\n",
    "\n",
    "Additionally, it's worth noting that the number of inspectors can be easily adjusted by changing this parameter. This flexibility allows for the optimization of the inspector team size based on specific needs and requirements.\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "adcf87697e394753"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def find_closest_node(graph, target_node):\n",
    "    \"\"\"\n",
    "    Find the closest matching node in a given graph for a target node name.\n",
    "\n",
    "    This function calculates the similarity between the target node name and each node in the graph\n",
    "    and returns the node with the highest similarity score.\n",
    "\n",
    "    Args:\n",
    "        graph (networkx.Graph): The graph containing nodes to search for a match.\n",
    "        target_node (str): The target node name for which to find the closest match.\n",
    "\n",
    "    Returns:\n",
    "        str: The node name from the graph that best matches the target node name.\n",
    "    \"\"\"\n",
    "    closest_node = None\n",
    "    max_similarity = -1\n",
    "\n",
    "    for node in graph.nodes:\n",
    "        similarity = fuzz.token_sort_ratio(target_node, node)\n",
    "        if similarity > max_similarity:\n",
    "            closest_node = node\n",
    "            max_similarity = similarity\n",
    "\n",
    "    return closest_node\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-03T18:28:14.361671Z",
     "start_time": "2023-11-03T18:28:14.340742300Z"
    }
   },
   "id": "c5486215f3c17bb9"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def find_optimal_locations(G, score_list, location_list, max_range, max_direct_range, number_of_inspectors):\n",
    "    \"\"\"\n",
    "    Selects a specified number of locations with the highest scores while considering constraints on minimum Euclidean and direct distances.\n",
    "\n",
    "\n",
    "    Args:\n",
    "        G (networkx.Graph): The graph representing the area where inspection locations are selected.\n",
    "        score_list (list): A list of scores for each location.\n",
    "        location_list (list): A list of location coordinates (x, y).\n",
    "        max_range (float): The maximum allowed Euclidean distance between selected locations.\n",
    "        max_direct_range (float): The maximum allowed direct (straight-line) distance between selected locations.\n",
    "        number_of_inspectors (int): The desired number of inspection locations to select.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of selected optimal inspection locations, each represented as a tuple (x, y).\n",
    "        list: A list of scores corresponding to the selected locations.\n",
    "    \"\"\"\n",
    "    final_locations = []\n",
    "    Sum = []\n",
    "\n",
    "    for item in range(len(score_list)):\n",
    "        extent = location_list[item]\n",
    "\n",
    "        if not str(extent) in G:\n",
    "            extent = find_closest_node(G, extent)\n",
    "            extent = ast.literal_eval(extent)\n",
    "\n",
    "        costs = [1e6]\n",
    "        direct_costs = [1e6]\n",
    "\n",
    "        for loc in final_locations:\n",
    "            direct_cost = ((loc[0] - extent[0])**2 + (loc[1] - extent[1])**2) ** (1/2)\n",
    "            direct_costs.append(direct_cost)\n",
    "\n",
    "            try:\n",
    "                cost = nx.shortest_path_length(G, str(extent), str(loc), weight='weight')\n",
    "            except:\n",
    "                cost = 1e6\n",
    "            costs.append(cost)\n",
    "\n",
    "            try:\n",
    "                cost = nx.shortest_path_length(G, str(loc), str(extent), weight='weight')\n",
    "            except:\n",
    "                cost = 2e6\n",
    "            costs.append(cost)\n",
    "\n",
    "        min_cost = min(costs)\n",
    "        min_direct_cost = min(direct_costs)\n",
    "\n",
    "        if (min_cost > max_range) and (min_direct_cost > max_direct_range):\n",
    "            final_locations.append(extent)\n",
    "            Sum.append(score_list[item])\n",
    "        # else:\n",
    "        #     print('Location is too close')\n",
    "\n",
    "        if len(final_locations) == number_of_inspectors:\n",
    "            break\n",
    "\n",
    "    return final_locations, Sum\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-03T18:28:14.381712500Z",
     "start_time": "2023-11-03T18:28:14.369685Z"
    }
   },
   "id": "b465a9b79de75751"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "def process_final_locations(final_locations, Sum):\n",
    "    \"\"\"\n",
    "    Convert lists of final inspection locations and corresponding scores into a DataFrame.\n",
    "\n",
    "    Args:\n",
    "        final_locations (list of tuples): A list of tuples representing inspection locations with (x, y) coordinates.\n",
    "        Sum (list): A list of scores corresponding to each inspection location.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame containing columns for 'X_value' (x-coordinate), 'Y_value' (y-coordinate), and 'Sum_weight' (score).\n",
    "    \"\"\"\n",
    "    data = final_locations\n",
    "    x, y = zip(*data)\n",
    "    x_values = list(x)\n",
    "    y_values = list(y)\n",
    "    \n",
    "    # # Assuming you have the 'DutchRDtoWGS84' function defined elsewhere\n",
    "    # wgs_coords = [functions.DutchRDtoWGS84(x, y) for x, y in zip(x_values, y_values)]\n",
    "    # wgs_x_values, wgs_y_values = zip(*wgs_coords)\n",
    "    \n",
    "    Inspector_locations = pd.DataFrame({'X_value': x_values, 'Y_value': y_values, 'Sum_weight': Sum})\n",
    "    display(Inspector_locations)\n",
    "    return Inspector_locations"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-03T18:28:14.431667Z",
     "start_time": "2023-11-03T18:28:14.381712500Z"
    }
   },
   "id": "a04581001bb7eef4"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "          X_value       Y_value  Sum_weight\n0    157715.96900  379454.41900    0.082284\n1    119810.34000  493682.34000    0.066861\n2     85860.07700  432976.59800    0.065860\n3    108158.90600  450448.65000    0.062600\n4     95910.01500  462530.83800    0.059399\n..            ...           ...         ...\n115  128428.44700  394457.72100    0.020799\n116  226915.85092  579821.64526    0.020633\n117  100002.90400  459765.09600    0.020623\n118  171203.31600  482428.90300    0.019934\n119  190580.58400  554403.80500    0.019779\n\n[120 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>X_value</th>\n      <th>Y_value</th>\n      <th>Sum_weight</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>157715.96900</td>\n      <td>379454.41900</td>\n      <td>0.082284</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>119810.34000</td>\n      <td>493682.34000</td>\n      <td>0.066861</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>85860.07700</td>\n      <td>432976.59800</td>\n      <td>0.065860</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>108158.90600</td>\n      <td>450448.65000</td>\n      <td>0.062600</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>95910.01500</td>\n      <td>462530.83800</td>\n      <td>0.059399</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>115</th>\n      <td>128428.44700</td>\n      <td>394457.72100</td>\n      <td>0.020799</td>\n    </tr>\n    <tr>\n      <th>116</th>\n      <td>226915.85092</td>\n      <td>579821.64526</td>\n      <td>0.020633</td>\n    </tr>\n    <tr>\n      <th>117</th>\n      <td>100002.90400</td>\n      <td>459765.09600</td>\n      <td>0.020623</td>\n    </tr>\n    <tr>\n      <th>118</th>\n      <td>171203.31600</td>\n      <td>482428.90300</td>\n      <td>0.019934</td>\n    </tr>\n    <tr>\n      <th>119</th>\n      <td>190580.58400</td>\n      <td>554403.80500</td>\n      <td>0.019779</td>\n    </tr>\n  </tbody>\n</table>\n<p>120 rows × 3 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "min_direct_range = 3000\n",
    "min_range = 10000\n",
    "number_of_inspectors = 120\n",
    "final_locations, Sum = find_optimal_locations(G, score_list, location_list, min_range, min_direct_range, number_of_inspectors)\n",
    "Inspector_locations = process_final_locations(final_locations, Sum)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-03T18:33:26.829812300Z",
     "start_time": "2023-11-03T18:28:14.400693400Z"
    }
   },
   "id": "78b6fdb5e4c88e28"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Creating Clones\n",
    "\n",
    "To evaluate the performance of the selected locations, we employ a unique approach: the creation of mirrored clones on the opposite side of the road. This mirroring process is essential because the road network lacks the necessary data to facilitate straightforward navigation of off and on ramps for travel in the opposite direction.\n",
    "\n",
    "The procedure for creating these clones involves determining the direction of the road using the RPE_code, which can be 'L' (left), 'R' (right), or '#' (indicating bidirectional roads). Based on the RPE_code, a new network is generated with the opposite road directions, and the nearest node in this new network is identified.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ae1c888a4dba1467"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "def other_road_side(node, G):\n",
    "    \"\"\"\n",
    "    Create a new graph containing only nodes on the opposite road side.\n",
    "\n",
    "    This function takes a node in a graph (G) and identifies its corresponding road side (RPE_CODE). It then creates a new graph (RPE_G) that includes only nodes with the opposite road side value, such as 'L' for 'R' or 'R' for 'L'. If the node's road side is '#' or if there are no nodes on the opposite road side, it returns None.\n",
    "\n",
    "    Args:\n",
    "        node: A node in the input graph G.\n",
    "        G (networkx.Graph): The original graph containing road-side information.\n",
    "\n",
    "    Returns:\n",
    "        networkx.Graph or None: A new graph containing nodes on the opposite road side or None if there are no such nodes.\n",
    "    \"\"\"\n",
    "    RPE = G.nodes[node]['RPE_CODE']\n",
    "    if RPE == \"L\":\n",
    "        value_to_match = \"R\"\n",
    "    if RPE == \"R\":\n",
    "        value_to_match = \"L\"\n",
    "    if RPE == \"#\":\n",
    "        return None\n",
    "    selected_nodes = []\n",
    "    for node in G.nodes:\n",
    "        RPE = G.nodes[node]['RPE_CODE']\n",
    "        if RPE == value_to_match:\n",
    "            selected_nodes.append(node)\n",
    "    RPE_G = nx.Graph()\n",
    "    RPE_G.add_nodes_from(selected_nodes)\n",
    "    return RPE_G"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-03T18:33:26.861734400Z",
     "start_time": "2023-11-03T18:33:26.831660500Z"
    }
   },
   "id": "6a8f0bc68d627012"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "def find_closest_node_other_side(graph, x1, y1):\n",
    "    \"\"\"\n",
    "    Find the closest node in a given graph based on Euclidean distance. (Used for finding the closest node on the other side of the road)\n",
    "\n",
    "    This function calculates the Euclidean distance between a specified point (x1, y1) and each node in the graph. It returns the node from the graph that is closest to the specified point, along with the calculated minimum distance.\n",
    "\n",
    "    Args:\n",
    "        graph (networkx.Graph): The graph containing nodes to search for the closest node.\n",
    "        x1 (float): The x-coordinate of the specified point.\n",
    "        y1 (float): The y-coordinate of the specified point.\n",
    "\n",
    "    Returns:\n",
    "        str: The node in the graph that is closest to the specified point.\n",
    "        float: The minimum Euclidean distance between the specified point and the closest node.\n",
    "    \"\"\"\n",
    "    closest_node = None\n",
    "    min_distance = float('inf')\n",
    "    for node in graph.nodes:\n",
    "        x2, y2 = functions.parse_coordinate(node)\n",
    "        distance = math.sqrt((x1 - x2) ** 2 + (y1 - y2) ** 2)\n",
    "\n",
    "        if distance < min_distance:\n",
    "            closest_node = node\n",
    "            min_distance = distance\n",
    "\n",
    "    return closest_node, min_distance\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-03T18:33:26.883399100Z",
     "start_time": "2023-11-03T18:33:26.850625100Z"
    }
   },
   "id": "a6184f777374f6d8"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "def create_clones(graph, node, max_range = 500):\n",
    "    \"\"\"\n",
    "    Create clone inspector locations on the opposite side of the road for a selected inspector location.\n",
    "\n",
    "    Args:\n",
    "        graph (networkx.Graph): The graph containing road-side information and nodes.\n",
    "        node: The selected inspector location node.\n",
    "        max_range (float): The maximum range within which the clone inspector location must be located on the opposite side of the road. Defaults to 500.\n",
    "\n",
    "    Returns:\n",
    "        tuple or None: A tuple representing the clone inspector location (x, y) if within max_range, or None if not.\n",
    "    \"\"\"\n",
    "    node = find_closest_node(graph, str(node))\n",
    "    x, y = functions.parse_coordinate(node)\n",
    "    RPE_G = other_road_side(node, graph)\n",
    "    if RPE_G == None:\n",
    "        return None\n",
    "    RPE_node, RPE_sim = find_closest_node_other_side(RPE_G, x, y)\n",
    "    if RPE_sim < max_range:\n",
    "        x_str, y_str = str(RPE_node).strip('()').split(', ')\n",
    "        RPE_node_x, RPE_node_y = (float(x_str), float(y_str))\n",
    "        return (RPE_node_x, RPE_node_y)  \n",
    "    else:\n",
    "        return None"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-03T18:33:26.902031300Z",
     "start_time": "2023-11-03T18:33:26.871621700Z"
    }
   },
   "id": "634cf88bd820ec8a"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "          X_value       Y_value  Sum_weight                     Other_side\n0    157715.96900  379454.41900    0.082284       (157697.714, 379481.622)\n1    119810.34000  493682.34000    0.066861           (119834.0, 493703.0)\n2     85860.07700  432976.59800    0.065860         (85885.947, 432987.14)\n3    108158.90600  450448.65000    0.062600       (108230.069, 450427.745)\n4     95910.01500  462530.83800    0.059399  (95915.967, 462499.839000001)\n..            ...           ...         ...                            ...\n115  128428.44700  394457.72100    0.020799       (128696.786, 394449.985)\n116  226915.85092  579821.64526    0.020633   (226911.18616, 579840.54611)\n117  100002.90400  459765.09600    0.020623       (100187.217, 459668.969)\n118  171203.31600  482428.90300    0.019934       (171184.947, 482445.059)\n119  190580.58400  554403.80500    0.019779       (190610.429, 554437.001)\n\n[120 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>X_value</th>\n      <th>Y_value</th>\n      <th>Sum_weight</th>\n      <th>Other_side</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>157715.96900</td>\n      <td>379454.41900</td>\n      <td>0.082284</td>\n      <td>(157697.714, 379481.622)</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>119810.34000</td>\n      <td>493682.34000</td>\n      <td>0.066861</td>\n      <td>(119834.0, 493703.0)</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>85860.07700</td>\n      <td>432976.59800</td>\n      <td>0.065860</td>\n      <td>(85885.947, 432987.14)</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>108158.90600</td>\n      <td>450448.65000</td>\n      <td>0.062600</td>\n      <td>(108230.069, 450427.745)</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>95910.01500</td>\n      <td>462530.83800</td>\n      <td>0.059399</td>\n      <td>(95915.967, 462499.839000001)</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>115</th>\n      <td>128428.44700</td>\n      <td>394457.72100</td>\n      <td>0.020799</td>\n      <td>(128696.786, 394449.985)</td>\n    </tr>\n    <tr>\n      <th>116</th>\n      <td>226915.85092</td>\n      <td>579821.64526</td>\n      <td>0.020633</td>\n      <td>(226911.18616, 579840.54611)</td>\n    </tr>\n    <tr>\n      <th>117</th>\n      <td>100002.90400</td>\n      <td>459765.09600</td>\n      <td>0.020623</td>\n      <td>(100187.217, 459668.969)</td>\n    </tr>\n    <tr>\n      <th>118</th>\n      <td>171203.31600</td>\n      <td>482428.90300</td>\n      <td>0.019934</td>\n      <td>(171184.947, 482445.059)</td>\n    </tr>\n    <tr>\n      <th>119</th>\n      <td>190580.58400</td>\n      <td>554403.80500</td>\n      <td>0.019779</td>\n      <td>(190610.429, 554437.001)</td>\n    </tr>\n  </tbody>\n</table>\n<p>120 rows × 4 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Inspector_locations['Other_side'] = Inspector_locations.apply(lambda row: create_clones(G, f\"({row['X_value']}, {row['Y_value']})\"), axis=1)\n",
    "display(Inspector_locations)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-03T18:35:20.724281900Z",
     "start_time": "2023-11-03T18:33:26.910607200Z"
    }
   },
   "id": "8745c875aa75f19d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Calculate Performance of Selected Locations\n",
    "\n",
    "The following code is an adaptation of the optimization model. It uses only the 120 chosen locations as input, rather than all the candidate points. The goal is to optimize the assignment of road inspectors to incidents, minimizing the total distance while satisfying capacity and service constraints.\n",
    "\n",
    "As the core process aligns with the optimization model, detailed explanations are omitted here and can be found in the \"Optimization Model\" notebook. The code is executed for a single incident day to reduce computation time.\n",
    "\n",
    "(Numerical results can be found at the bottom)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dc84cc415bdb2b21"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "def filter_incidents(select_day, inc_df):\n",
    "    \"\"\"\n",
    "    Filter and preprocess incidents for a selected day from the total incidents DataFrame.\n",
    "\n",
    "    Args:\n",
    "        select_day (datetime.date): The date for which incidents will be filtered.\n",
    "        inc_df (pd.DataFrame): The total incidents DataFrame containing incident data.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A filtered and preprocessed DataFrame with incidents that occurred on the selected day. The DataFrame is prepared for future calculations with additional columns.\n",
    "    \"\"\"\n",
    "    \n",
    "    # filter to incidents which happened on selected_day\n",
    "    filt_inc = inc_df[inc_df['starttime_new'].dt.date == select_day]\n",
    "    filt_inc = filt_inc.copy()\n",
    "\n",
    "    # add dutch rd coordinates\n",
    "    DutchRD = filt_inc.apply(lambda x: functions.WGS84toDutchRD(x.primaire_locatie_lengtegraad, \n",
    "                                                                x.primaire_locatie_breedtegraad), axis=1)\n",
    "    filt_inc['dutch_rd_x'] = DutchRD.apply(lambda x: x[0])\n",
    "    filt_inc['dutch_rd_y'] = DutchRD.apply(lambda x: x[1])\n",
    "\n",
    "    # add columns to the DF which will be used later\n",
    "    filt_inc['Node'] = None\n",
    "    filt_inc['Node_distance_to_incident'] = None\n",
    "    filt_inc['Node_distance_line'] = None\n",
    "    filt_inc['Node_line'] = None\n",
    "    filt_inc['Node_RPE'] = None\n",
    "\n",
    "    return filt_inc"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-03T18:35:20.751482700Z",
     "start_time": "2023-11-03T18:35:20.724281900Z"
    }
   },
   "id": "8356beec3d95a4d5"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "def find_nearest_node_incidents_new(x, y, gdf, tolerance=25):\n",
    "    \"\"\"\n",
    "    Find the nearest linestring in a GeoDataFrame to a given point (x, y) and calculate distances.\n",
    "\n",
    "    This function takes a point with coordinates (x, y) and a GeoDataFrame (gdf) containing linestrings. It determines which linestring from the network is located closest to the specified point and calculates the distance to that linestring. It also checks if the point is within a specified tolerance distance to the nearest linestring.\n",
    "\n",
    "    Args:\n",
    "        x (float): The x-coordinate of the point.\n",
    "        y (float): The y-coordinate of the point.\n",
    "        gdf (geopandas.GeoDataFrame): The GeoDataFrame containing linestrings.\n",
    "        tolerance (float, optional): The tolerance distance within which the point is considered to be on the nearest linestring. Defaults to 25.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing information about the nearest linestring and distances, including:\n",
    "            - 'Node': The nearest node coordinates.\n",
    "            - 'Line': The nearest linestring.\n",
    "            - 'RPE': The road-side information of the nearest linestring.\n",
    "            - 'Total Distance to Line': The total distance to the nearest linestring.\n",
    "            - 'Distance to Incident': The Euclidean distance from the point to the nearest node on the linestring.\n",
    "            If the point is not within the tolerance distance, the dictionary values are set to None.\n",
    "    \"\"\"\n",
    "    point = f\"POINT ({x} {y})\"\n",
    "    \n",
    "    # create a gdf of the point and all lines in the network\n",
    "    gdf_line = gpd.GeoDataFrame(gdf['geometry'])\n",
    "    \n",
    "    # crs is determined by the crs of the linestrings in the network\n",
    "    gdf_point = gpd.GeoDataFrame(geometry=[shapely.wkt.loads(point)], crs=gdf_line.crs)\n",
    "    \n",
    "    # finds the nearest linestring and merges the two gdf's together\n",
    "    df_n = gpd.sjoin_nearest(gdf_point, gdf_line).merge(gdf_line, left_on=\"index_right\", right_index=True)\n",
    "    \n",
    "    # calculates the distance from the point to the linestring\n",
    "    df_n['distance'] = df_n.apply(lambda r: r[\"geometry_x\"].distance(r[\"geometry_y\"]), axis=1)\n",
    "    \n",
    "    # if two or more linestrings are at an equal distance from the point it only considers the first linestring\n",
    "    if len(df_n) > 1:\n",
    "        df_n = pd.DataFrame(df_n.iloc[0]).T\n",
    "        df_n = gpd.GeoDataFrame(df_n, geometry='geometry_y', crs=gdf_line.crs)\n",
    "    \n",
    "    # checks whether the point is located within the tolarance distance\n",
    "    if df_n['distance'].min() < tolerance:\n",
    "        \n",
    "        # I copied this from Klaas, I'm not sure why he takes the last coordinate\n",
    "        nearest_node = df_n['geometry_y'].item().coords[-1]\n",
    "        nearest_line = df_n['geometry_y'].item()\n",
    "        nearest_RPE = gdf.iloc[df_n['index_right']]['RPE_CODE'].item()\n",
    "        total_distance_to_nearest_line = gdf.iloc[df_n['index_right']]['ENDAFSTAND'].item()\n",
    "        distance_to_incident = np.sqrt((nearest_node[0] - x) ** 2 + (nearest_node[1] - y) ** 2)\n",
    "\n",
    "        return {'Node': nearest_node,\n",
    "                'Line': nearest_line,\n",
    "                'RPE': nearest_RPE,\n",
    "                'Total Distance to Line': total_distance_to_nearest_line,\n",
    "                'Distance to Incident': distance_to_incident}\n",
    "    \n",
    "    # if the point is not within the tolarance distance it returns an empyt dict\n",
    "    else:\n",
    "        return {'Node': None,\n",
    "                'Line': None,\n",
    "                'RPE': None,\n",
    "                'Total Distance to Line': None,\n",
    "                'Distance to Incident': None}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-03T18:35:20.777656800Z",
     "start_time": "2023-11-03T18:35:20.742011700Z"
    }
   },
   "id": "17e09dbd295ebf0b"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "def calculate_values(row):\n",
    "    \"\"\"\n",
    "    Calculate and store values related to the nearest node and linestring for an incident.\n",
    "\n",
    "    Args:\n",
    "        row (pd.Series): A row from the incidents DataFrame containing incident data.\n",
    "        gdf (geopandas.GeoDataFrame): The GeoDataFrame containing linestrings for the network.\n",
    "\n",
    "    Returns:\n",
    "        pd.Series: The input row with additional columns storing calculated values, including:\n",
    "            - 'Node': The nearest node coordinates.\n",
    "            - 'Node_distance_line': The total distance to the nearest linestring.\n",
    "            - 'Node_line': The nearest linestring.\n",
    "            - 'Node_distance_to_incident': The Euclidean distance from the incident to the nearest node.\n",
    "            - 'Node_RPE': The road-side information of the nearest linestring.\n",
    "    \"\"\"\n",
    "\n",
    "    x = row['dutch_rd_x']\n",
    "    y = row['dutch_rd_y']\n",
    "    result = find_nearest_node_incidents_new(x, y, gdf)\n",
    "    \n",
    "    row[\"Node\"] = result['Node']\n",
    "    row[\"Node_distance_line\"] = result['Total Distance to Line']\n",
    "    row[\"Node_line\"] = result['Line']\n",
    "    row['Node_distance_to_incident'] = result['Distance to Incident']\n",
    "    row['Node_RPE'] = result['RPE']\n",
    "    \n",
    "    return row"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-03T18:35:20.801839900Z",
     "start_time": "2023-11-03T18:35:20.761024800Z"
    }
   },
   "id": "234385ab885a1d3b"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "def drop_inc_out_of_range(inc_df, print_bool=False):\n",
    "    \"\"\"\n",
    "    Drop incidents that are more than 25 meters from the nearest network link.\n",
    "\n",
    "    Args:\n",
    "        inc_df (pd.DataFrame): The incidents DataFrame.\n",
    "        print_bool (bool, optional): If True, the function prints the percentage of dropped rows. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame containing incidents that are within 25 meters of the nearest road network link.\n",
    "    \"\"\"\n",
    "    \n",
    "    nan_count = inc_df['Node'].isna().sum()\n",
    "    if print_bool:\n",
    "        print(f'Percentage of dropped rows: {(nan_count / len(inc_df) * 100):.2f}%, '+\n",
    "               'because these incidents are more than 25 meters from the closest road.')\n",
    "\n",
    "    # all incidents which are too far away from the network are dropped\n",
    "    incidents = inc_df.dropna().reset_index(drop=True)\n",
    "    \n",
    "    return incidents"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-03T18:35:20.801839900Z",
     "start_time": "2023-11-03T18:35:20.780617Z"
    }
   },
   "id": "6e049479bb2ce507"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "def process_inspectors_data(inspectors_df, G):\n",
    "    \"\"\"\n",
    "    Process inspector location data and update it with nearest road nodes.\n",
    "\n",
    "    Args:\n",
    "        inspectors_df (pd.DataFrame): DataFrame containing inspector location data.\n",
    "        G (networkx.Graph): Graph representing road networks for finding nearest road nodes.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Processed inspector location data with updated coordinates.\n",
    "    \"\"\"\n",
    "    # Rename and select relevant columns\n",
    "    inspectors_df.rename(columns={'Other_side': 'Clone'}, inplace=True)\n",
    "    inspectors_df = inspectors_df[['X_value', 'Y_value', 'Clone']]\n",
    "\n",
    "    # Convert all coordinates to string\n",
    "    inspectors_df['Main'] = inspectors_df.apply(lambda row: str((row['X_value'], row['Y_value'])), axis=1)\n",
    "    inspectors_df = inspectors_df[['Main', 'Clone']]\n",
    "\n",
    "    # Add the coordinates from the find_closest_node function\n",
    "    inspectors_df['Main_updated'] = inspectors_df['Main'].apply(lambda x: find_closest_node(G, x))\n",
    "    inspectors_df['Clone_updated'] = inspectors_df['Clone'].apply(lambda x: find_closest_node(G, x))\n",
    "    \n",
    "    return inspectors_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-03T18:35:20.801839900Z",
     "start_time": "2023-11-03T18:35:20.790787800Z"
    }
   },
   "id": "88aed9f7b11c51ba"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "def create_empty_cost_M(uni_cand, inc_df, G):\n",
    "    \"\"\"\n",
    "    Create an empty cost matrix for candidate and incident nodes.\n",
    "\n",
    "    Args:\n",
    "        uni_cand (pd.DataFrame): A DataFrame containing candidate node information, including 'Main_updated' and 'Clone_updated'.\n",
    "        inc_df (pd.DataFrame): The incidents DataFrame.\n",
    "        G (networkx.Graph): The graph containing road network information.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: An empty cost matrix with candidate nodes as rows and incident nodes as columns.\n",
    "        list: The column names (incident nodes) extracted from the incidents DataFrame and present in the graph 'G'.\n",
    "    \"\"\"\n",
    "\n",
    "    num_rows = len(uni_cand)\n",
    "    placeholder_value = None  # You can use np.nan or any other value as a placeholder\n",
    "    col_names = [str(node) for node in list(inc_df['Node']) if str(node) in G.nodes()]\n",
    "    main_names = uni_cand['Main_updated'].values\n",
    "    clone_names = uni_cand['Clone_updated'].values\n",
    "    num_columns = len(col_names)\n",
    "    data = [[placeholder_value] * num_columns for _ in range(num_rows)]\n",
    "    cost_M = pd.DataFrame(data, columns=col_names)\n",
    "    cost_M.insert(0, 'Main', main_names)\n",
    "    cost_M.insert(1, 'Clone', clone_names)\n",
    "    \n",
    "    return cost_M, col_names"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-03T18:35:20.860385700Z",
     "start_time": "2023-11-03T18:35:20.801839900Z"
    }
   },
   "id": "ecbc671de30f00bc"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "def parse_coordinate(coordinate_string):\n",
    "    \"\"\"\n",
    "    Parse a string of coordinate values to obtain usable x and y coordinates.\n",
    "\n",
    "    Args:\n",
    "        coordinate_string (str): A string containing the coordinate values in the format \"(x, y)\".\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the parsed x and y coordinates as floats.\n",
    "    \"\"\"\n",
    "    # Remove parentheses and split the string by comma\n",
    "    if coordinate_string[-2] == '.':\n",
    "        coordinate_string = coordinate_string[:-2]\n",
    "    cleaned_string = coordinate_string.strip('()')\n",
    "    x_str, y_str = cleaned_string.split(',')\n",
    "\n",
    "    # Convert the string values to floats\n",
    "    x = float(x_str.strip())\n",
    "    y = float(y_str.strip())\n",
    "\n",
    "    return x, y"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-03T18:35:20.872107400Z",
     "start_time": "2023-11-03T18:35:20.824958900Z"
    }
   },
   "id": "de67f0358d5400ad"
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "def calculate_cost_matrix(cost_M, G, print_bool=False):\n",
    "    \"\"\"\n",
    "    Fill in all values of the cost matrix based on network distances.\n",
    "\n",
    "    This function populates the cost matrix with values representing distances or costs between candidate nodes and incident nodes. It uses network-based distances where possible, including Euclidean distance and shortest path lengths, while considering constraints for large distances.\n",
    "\n",
    "    Args:\n",
    "        cost_M (pd.DataFrame): An empty cost matrix with candidate nodes as rows and incident nodes as columns.\n",
    "        G (networkx.Graph): The graph containing road network information.\n",
    "        print_bool (bool, optional): If True, the function prints the time taken for the calculations. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The filled cost matrix with calculated distances or costs between candidate and incident nodes.\n",
    "    \"\"\"\n",
    "    \n",
    "    t0 = time.time()\n",
    "    cost_M = cost_M.copy()\n",
    "    no_counter = 0\n",
    "    \n",
    "    for row_idx in range(cost_M.shape[0]):\n",
    "\n",
    "        main_node = cost_M.iloc[row_idx, 0]\n",
    "        clone_node = cost_M.iloc[row_idx, 1]\n",
    "\n",
    "        main_node_x, main_node_y = parse_coordinate(main_node)\n",
    "        \n",
    "        for col_idx in np.arange(2, cost_M.shape[1]):\n",
    "\n",
    "            # store coordinates of incident node as tuple\n",
    "            goal_node = parse_coordinate(cost_M.columns[col_idx])\n",
    "\n",
    "            # calculate euclidean distance\n",
    "            dx = main_node_x - goal_node[0]\n",
    "            dy = main_node_y - goal_node[1]\n",
    "            distance = np.sqrt(dx*dx + dy*dy)\n",
    "\n",
    "            # if euclidean distance is larger than 50 km set a large value as cost\n",
    "            if distance > 50000:\n",
    "                cost = 1e9\n",
    "\n",
    "            # otherwise try to calculate shortest path\n",
    "            else:\n",
    "                try:\n",
    "                    cost_main = nx.shortest_path_length(G, str(main_node), str(goal_node), \n",
    "                                                   weight='weight')\n",
    "                    try:\n",
    "                        cost_clone = nx.shortest_path_length(G, str(clone_node), str(goal_node), \n",
    "                                                       weight='weight')\n",
    "                    except:\n",
    "                        cost = cost_main\n",
    "                    else:\n",
    "                        # add 2 km to the cost of the clone node and then take min cost\n",
    "                        cost = np.min([cost_main, cost_clone + 2000])\n",
    "\n",
    "                # if shortest path still throws an error then store other large value\n",
    "                except:\n",
    "                    no_counter += 1\n",
    "                    cost = 2e9\n",
    "\n",
    "            # store calculated cost in the correct postion in matrix\n",
    "            cost_M.iloc[row_idx, col_idx] = cost\n",
    "            \n",
    "    t1 = time.time()\n",
    "\n",
    "    total = t1-t0\n",
    "    if print_bool:\n",
    "        print(f'calculating the whole cost matrix took: {total/60:.2f} minutes')\n",
    "        \n",
    "    return cost_M"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-03T18:35:20.872107400Z",
     "start_time": "2023-11-03T18:35:20.841821400Z"
    }
   },
   "id": "4f8e832712151375"
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "def drop_unconnected_incidents(cost_M, print_bool=False):\n",
    "    \"\"\"\n",
    "    Remove incidents with excessively large costs from the cost matrix.\n",
    "\n",
    "    This function removes incidents from the cost matrix if the cost to the nearest candidate node is larger than 1,000 kilometers. \n",
    "\n",
    "    Args:\n",
    "        cost_M (pd.DataFrame): The cost matrix with candidate nodes as rows and incident nodes as columns.\n",
    "        print_bool (bool, optional): If True, the function prints the percentage of dropped incidents. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The cost matrix with unconnected incidents removed.\n",
    "    \"\"\"\n",
    "    cost_M = cost_M.copy()\n",
    "    \n",
    "    # get the minimum cost values for each incident node\n",
    "    min_values = cost_M.iloc[:, 2:].min()\n",
    "    columns_to_drop = []\n",
    "\n",
    "    # iterate over al min costs and if this is larger than 1000 km add it to the drop list\n",
    "    for col, val in min_values.items():\n",
    "        if pd.notna(val) and val > 1e6:\n",
    "            columns_to_drop.append(col)\n",
    "\n",
    "    cost_M.drop(columns=columns_to_drop, inplace=True)\n",
    "    if print_bool:\n",
    "        print(f'{(len(columns_to_drop) / len(min_values) * 100):.2f}% of the incidents are '+\n",
    "              'dropped because there is no route possible from any candidate node')\n",
    "    \n",
    "    return cost_M"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-03T18:35:20.881485Z",
     "start_time": "2023-11-03T18:35:20.860945Z"
    }
   },
   "id": "4784e0c08cc95c4d"
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "def subtract_dist_to_node(cost_M, inc):\n",
    "    \"\"\"\n",
    "    Adjust the cost matrix by subtracting the distance from incidents to their nearest road nodes.\n",
    "\n",
    "    Args:\n",
    "        cost_M (pd.DataFrame): A cost matrix with distances or costs between candidate nodes and incidents.\n",
    "        inc (pd.DataFrame): A DataFrame containing information about incidents, including incident locations and distances to the nearest road nodes.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: An adjusted cost matrix with reduced costs after subtracting distances to nearest road nodes.\n",
    "        list: A list of incident locations (Dutch RD coordinates).\n",
    "    \"\"\"\n",
    "    incidents_loc = []\n",
    "    distance_store = []\n",
    "    result_df = cost_M.copy()  # Create a copy of the DataFrame\n",
    "\n",
    "    # iterate over all incident nodes\n",
    "    for name in cost_M.iloc[:, 2:].columns:\n",
    "        if name[-2] == '.':\n",
    "            count = int(name[-1])\n",
    "            N = name[:-2]\n",
    "        else:\n",
    "            count = 0\n",
    "            N = name\n",
    "\n",
    "        # get the data for the incident node\n",
    "        match = inc[inc[\"Node\"].astype(str) == N]\n",
    "\n",
    "        # get the distance from the incident to the end node\n",
    "        dist = match['Node_distance_to_incident'].values\n",
    "        distance_to_node = dist[count]\n",
    "\n",
    "        # get the dutch rd coordinates of the incident\n",
    "        incident_loc = (match[\"dutch_rd_x\"].values[0], match[\"dutch_rd_y\"].values[0])\n",
    "\n",
    "        incidents_loc.append(incident_loc)\n",
    "        distance_store.append(distance_to_node)\n",
    "\n",
    "    result_df.iloc[:, 2:] -= distance_store\n",
    "    result_df.iloc[:, 2:] = result_df.iloc[:, 2:].abs()\n",
    "    \n",
    "    return result_df, incidents_loc"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-03T18:35:20.920131800Z",
     "start_time": "2023-11-03T18:35:20.881485Z"
    }
   },
   "id": "bfb4bad32e0d83b8"
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "def store_cost_matrix_in_arrays(cost_M):\n",
    "    \"\"\"\n",
    "    Store the values in the cost matrix in arrays for candidates and incidents.\n",
    "\n",
    "    Args:\n",
    "        cost_M (pd.DataFrame): The cost matrix with candidate nodes as rows and incident nodes as columns.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: The cost matrix values for distances or costs between candidates and incidents.\n",
    "        np.ndarray: The coordinates of candidate nodes.\n",
    "        np.ndarray: The coordinates of incident nodes.\n",
    "    \"\"\"\n",
    "    # store the values in arrays\n",
    "    cost_matrix = np.array(cost_M.iloc[:, 2:].values)\n",
    "    final_incidents_nodes = np.array(cost_M.columns[2:])\n",
    "    final_candidates = np.array(cost_M['Main'].values)\n",
    "\n",
    "    # store the converted coordinate values into a new array\n",
    "    candidates = np.array([parse_coordinate(node) for node in final_candidates])\n",
    "    incidents = np.array([parse_coordinate(node) for node in final_incidents_nodes])\n",
    "    \n",
    "    return cost_matrix, candidates, incidents"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-03T18:35:20.920646700Z",
     "start_time": "2023-11-03T18:35:20.901715200Z"
    }
   },
   "id": "d104136aedd7ac40"
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "def run_gurobi_model(selected_day, cost_M, cand_arr, inc_arr, print_bool=False):\n",
    "    \"\"\"\n",
    "    Create a Gurobi optimization model for assigning inspectors to incidents.\n",
    "\n",
    "    This function sets up a Gurobi optimization model, adds the objective function and constraints, and then runs the optimization to determine the assignment of inspectors to incidents. It returns the results, including the selected inspector nodes and a binary matrix indicating the assignment of inspectors to incidents.\n",
    "\n",
    "    Args:\n",
    "        selected_day (datetime.date): The date for which the optimization is performed.\n",
    "        cost_M (np.ndarray): A cost matrix with distances or costs between candidate nodes and incidents.\n",
    "        cand_arr (np.ndarray): Coordinates of candidate nodes.\n",
    "        inc_arr (np.ndarray): Coordinates of incident nodes.\n",
    "        print_bool (bool, optional): If True, the function prints summary results. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of results including the selected day, number of inspectors, number of incidents,\n",
    "              objective function value, average response time (in seconds), and average response time (in minutes).\n",
    "        list: A list of selected inspector nodes.\n",
    "        np.ndarray: A binary matrix indicating the assignment of inspectors to incidents.\n",
    "    \"\"\"\n",
    "    # initialise model\n",
    "    model = Model(\"Road inspectors\")\n",
    "    \n",
    "    # Setting up the indices\n",
    "    N = np.arange(cand_arr.shape[0])\n",
    "    K = np.arange(inc_arr.shape[0])\n",
    "\n",
    "    # Parameters\n",
    "    inspector_cap = 10 # the maximum amount of incidents an inspector can handle in a day\n",
    "    N_inspectors = 120 # the maximum amount of inspectors\n",
    "    speed = 100 # a constant speed value in km/h\n",
    "\n",
    "    if inspector_cap * N_inspectors < inc_arr.shape[0]:\n",
    "        raise ValueError(\"Not enough inspectors!\")\n",
    "        \n",
    "    pair = [(i, k) for i in N for k in K]\n",
    "\n",
    "    # Setting up the variables\n",
    "    x = model.addVars(pair, vtype=GRB.BINARY, name=\"x\")\n",
    "    c = model.addVars(N, vtype=GRB.BINARY, name=\"c\")\n",
    "\n",
    "    model.Params.MIPGap = 0.01 # set the threshold value at which the optimisation stops to 1.0%\n",
    "    model.Params.IntegralityFocus=0\n",
    "    model.update()\n",
    "    \n",
    "    # Objective function: Minimise the total travel cost\n",
    "    model.setObjective(quicksum(cost_M[i, k] * x[i, k] for i in N for k in K),\n",
    "                       GRB.MINIMIZE)\n",
    "    \n",
    "    # Constraints: All incidents must be handled\n",
    "    model.addConstrs(quicksum(x[i, k] for i in N) == 1 for k in K)\n",
    "    \n",
    "    # Constraints: Inspector capacity\n",
    "    model.addConstrs(quicksum(x[i, k] for k in K) <= (inspector_cap * c[i]) for i in N)\n",
    "    \n",
    "    # Constraints: Number of inspectors\n",
    "    model.addConstr(quicksum(c[i] for i in N) <= N_inspectors)\n",
    "    \n",
    "    # Run the model\n",
    "    model.update()\n",
    "    model.optimize()\n",
    "    \n",
    "    # Collect the results\n",
    "    inspectors = []\n",
    "\n",
    "\n",
    "\n",
    "    # Collect the matching\n",
    "    match_arr = np.zeros((len(N), len(K)))\n",
    "    for i in N:\n",
    "        for k in K:\n",
    "            match_arr[i, k] = x[i, k].x\n",
    "\n",
    "    for i in N:\n",
    "        if c[i].x == 1:\n",
    "            inspectors.append(i)\n",
    "    \n",
    "    # Calculate the average response time in seconds\n",
    "    ave_time = model.ObjVal / len(inc_arr) / 1000 / speed * 3600\n",
    "    # Collect objective date, number of inspectors, number of incidents,\n",
    "    # objective function values, average response time[sec], average response time [min]\n",
    "    output = [selected_day, len(N), len(K),\n",
    "               model.ObjVal, ave_time, ave_time/60]\n",
    "            \n",
    "    # Summary of results\n",
    "    if print_bool:\n",
    "        print(f'Minimum total cost is {model.ObjVal/1000:.2f} km')\n",
    "        print(f'Number of inspectors is {len(inspectors)}')\n",
    "        print(f'The distance per inspector is {model.ObjVal / len(inspectors) / 1000 :.2f} km')\n",
    "\n",
    "        \n",
    "        print(f'Average time to reach the incident is {ave_time//60:.0f} minutes and {ave_time%60:.0f} seconds')\n",
    "    \n",
    "    return output, inspectors, match_arr"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-03T18:35:20.941738800Z",
     "start_time": "2023-11-03T18:35:20.931774400Z"
    }
   },
   "id": "b14e17340e14352"
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "def run_everything_for_optimisation (selected_day, all_incidents, inspectors_df, G):\n",
    "    \"\"\"\n",
    "    Run all calculations for the optimization model.\n",
    "\n",
    "    This function performs a series of calculations and optimization steps for the road inspector allocation model based on the following input parameters:\n",
    "    \n",
    "    Args:\n",
    "        selected_day (datetime.date): The day for which calculations are performed.\n",
    "        all_incidents (pd.DataFrame): DataFrame containing information about all incidents.\n",
    "        inspectors_df (pd.DataFrame): DataFrame with inspector location data.\n",
    "        G (networkx.Graph): Network graph representing road networks.\n",
    "        input_day (str): The input day used in file naming or other purposes.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the following elements:\n",
    "            - output (list): Results including the number of inspectors, incidents, objective value, average response time in seconds, and average response time in minutes.\n",
    "            - match_arr (numpy.ndarray): A 2D array representing the assignment of inspectors to incidents.\n",
    "            - incidents_location (pd.DataFrame): DataFrame containing incident locations.\n",
    "            - inspectors (list): List of inspector locations selected by the optimization model.\n",
    "    \"\"\"\n",
    "    inspectors_df = process_inspectors_data(inspectors_df, G)\n",
    "    \n",
    "    filtered_incidents = filter_incidents(selected_day, all_incidents)\n",
    "\n",
    "    incidents_results = filtered_incidents.apply(calculate_values, axis=1)\n",
    "    \n",
    "    incidents = drop_inc_out_of_range(incidents_results)\n",
    "\n",
    "    cost_matrix, column_names = create_empty_cost_M(inspectors_df, incidents, G)\n",
    "\n",
    "    fill_cost_matrix = calculate_cost_matrix(cost_matrix, G)\n",
    "\n",
    "    clean_cost_matrix = drop_unconnected_incidents(fill_cost_matrix)\n",
    "    \n",
    "    end_cost_matrix, incidents_loc = subtract_dist_to_node(clean_cost_matrix, incidents)\n",
    "    \n",
    "    incidents_location = pd.DataFrame(incidents_loc, columns=['x', 'y'])\n",
    "\n",
    "    cost_matrix, candidates, incidents = store_cost_matrix_in_arrays(end_cost_matrix)\n",
    "\n",
    "    if cost_matrix.shape[0] != candidates.shape[0] or cost_matrix.shape[1] != incidents.shape[0]:\n",
    "        raise ValueError(\"Dimensions do not match\")\n",
    "\n",
    "    output, inspectors, match_arr = run_gurobi_model(selected_day, cost_matrix, candidates, incidents, print_bool=True)\n",
    "\n",
    "    return output, match_arr, incidents_location, inspectors\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-03T18:35:20.980111600Z",
     "start_time": "2023-11-03T18:35:20.941738800Z"
    }
   },
   "id": "6a38bbef9eac12c9"
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2024-10-10\n",
      "Set parameter MIPGap to value 0.01\n",
      "Gurobi Optimizer version 10.0.3 build v10.0.3rc0 (win64)\n",
      "\n",
      "CPU model: Intel(R) Core(TM) i7-8750H CPU @ 2.20GHz, instruction set [SSE2|AVX|AVX2]\n",
      "Thread count: 6 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Optimize a model with 369 rows, 29880 columns and 59760 nonzeros\n",
      "Model fingerprint: 0xbc7ccb80\n",
      "Variable types: 0 continuous, 29880 integer (29880 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+01]\n",
      "  Objective range  [1e+02, 2e+09]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+00, 1e+02]\n",
      "Warning: Model contains large objective coefficients\n",
      "         Consider reformulating model or setting NumericFocus parameter\n",
      "         to avoid numerical issues.\n",
      "Found heuristic solution: objective 1.890039e+11\n",
      "Presolve removed 1 rows and 120 columns\n",
      "Presolve time: 0.08s\n",
      "Presolved: 368 rows, 29760 columns, 59520 nonzeros\n",
      "Variable types: 0 continuous, 29760 integer (29760 binary)\n",
      "Found heuristic solution: objective 3.013926e+09\n",
      "\n",
      "Root relaxation: objective 2.327262e+06, 249 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "*    0     0               0    2327261.6278 2327261.63  0.00%     -    0s\n",
      "\n",
      "Explored 1 nodes (249 simplex iterations) in 0.16 seconds (0.12 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 3: 2.32726e+06 3.01393e+09 1.89004e+11 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 2.327261627832e+06, best bound 2.327261627832e+06, gap 0.0000%\n",
      "Minimum total cost is 2327.26 km\n",
      "Number of inspectors is 120\n",
      "The distance per inspector is 19.39 km\n",
      "Average time to reach the incident is 5 minutes and 38 seconds\n"
     ]
    }
   ],
   "source": [
    "day = '2019-07-31'\n",
    "selected_day = datetime.strptime(day, '%Y-%m-%d').date()\n",
    "output, match_arr, incidents_location, inspectors = run_everything_for_optimisation(selected_day, all_incidents, Inspector_locations, G)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-03T18:39:56.031942500Z",
     "start_time": "2023-11-03T18:35:20.980622Z"
    }
   },
   "id": "fdf8cfb5343c2b05"
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calibration results for: 2019-07-31\n",
      "\n",
      "Minimum Total Cost: 2327.26 km\n",
      "Number of Inspectors: 120\n",
      "Distance per Inspector: 19.39 km\n",
      "Average Time to Reach Incidents: 5 minutes and 38 seconds\n"
     ]
    }
   ],
   "source": [
    "print(\"Calibration results for:\", output[0])\n",
    "print()\n",
    "print(\"Minimum Total Cost:\", f\"{output[3] / 1000:.2f}\", \"km\")\n",
    "print(\"Number of Inspectors:\", len(inspectors))\n",
    "print(\"Distance per Inspector:\", f\"{output[3] / len(inspectors) / 1000 :.2f}\", \"km\")\n",
    "print(\"Average Time to Reach Incidents:\", f\"{output[4]//60:.0f} minutes and {output[4]%60:.0f} seconds\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-03T18:39:56.051614700Z",
     "start_time": "2023-11-03T18:39:56.031091700Z"
    }
   },
   "id": "fd5c6b8f21c745f5"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
